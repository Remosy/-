<html>
<head>
<title>test1.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #000080; font-weight: bold;}
.s1 { color: #000000;}
.s2 { color: #808080; font-style: italic;}
.s3 { color: #0000ff;}
.s4 { color: #008080; font-weight: bold;}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test1.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span>torch
<span class="s0">from </span>torch.autograd <span class="s0">import </span>Variable
<span class="s0">from </span>torch.autograd <span class="s0">import </span>Function
<span class="s0">from </span>torchvision <span class="s0">import </span>models
<span class="s0">from </span>torchvision <span class="s0">import </span>utils
<span class="s0">import </span>cv2
<span class="s0">import </span>sys
<span class="s0">import </span>numpy <span class="s0">as </span>np
<span class="s0">import </span>argparse

<span class="s0">class </span>FeatureExtractor():
    <span class="s2">&quot;&quot;&quot; Class for extracting activations and 
    registering gradients from targetted intermediate layers &quot;&quot;&quot;</span>
    <span class="s0">def </span>__init__(self, model, target_layers):
        self.model = model
        self.target_layers = target_layers
        self.gradients = []

    <span class="s0">def </span>save_gradient(self, grad):
    	self.gradients.append(grad)

    <span class="s0">def </span>__call__(self, x):
        outputs = []
        self.gradients = []
        <span class="s0">for </span>name, module <span class="s0">in </span>self.model._modules.items():
            x = module(x)
            <span class="s0">if </span>name <span class="s0">in </span>self.target_layers:
                x.register_hook(self.save_gradient)
                outputs += [x]
        <span class="s0">return </span>outputs, x

<span class="s0">class </span>ModelOutputs():
	<span class="s2">&quot;&quot;&quot; Class for making a forward pass, and getting: 
    1. The network output. 
    2. Activations from intermeddiate targetted layers. 
    3. Gradients from intermeddiate targetted layers. &quot;&quot;&quot;</span>
	<span class="s0">def </span>__init__(self, model, target_layers):
		self.model = model
		self.feature_extractor = FeatureExtractor(self.model.features, target_layers)

	<span class="s0">def </span>get_gradients(self):
		<span class="s0">return </span>self.feature_extractor.gradients

	<span class="s0">def </span>__call__(self, x):
		target_activations, output  = self.feature_extractor(x)
		output = output.view(output.size(<span class="s3">0</span>), -<span class="s3">1</span>)
		output = self.model.classifier(output)
		<span class="s0">return </span>target_activations, output

<span class="s0">def </span>preprocess_image(img):
	means=[<span class="s3">0.485</span>, <span class="s3">0.456</span>, <span class="s3">0.406</span>]
	stds=[<span class="s3">0.229</span>, <span class="s3">0.224</span>, <span class="s3">0.225</span>]

	preprocessed_img = img.copy()[: , :, ::-<span class="s3">1</span>]
	<span class="s0">for </span>i <span class="s0">in </span>range(<span class="s3">3</span>):
		preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]
		preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]
	preprocessed_img = \
		np.ascontiguousarray(np.transpose(preprocessed_img, (<span class="s3">2</span>, <span class="s3">0</span>, <span class="s3">1</span>)))
	preprocessed_img = torch.from_numpy(preprocessed_img)
	preprocessed_img.unsqueeze_(<span class="s3">0</span>)
	input = Variable(preprocessed_img, requires_grad = <span class="s0">True</span>)
	<span class="s0">return </span>input

<span class="s0">def </span>show_cam_on_image(img, mask):
	heatmap = cv2.applyColorMap(np.uint8(<span class="s3">255</span>*mask), cv2.COLORMAP_JET)
	heatmap = np.float32(heatmap) / <span class="s3">255</span>
	cam = heatmap + np.float32(img)
	cam = cam / np.max(cam)
	cv2.imwrite(<span class="s4">&quot;cam.jpg&quot;</span>, np.uint8(<span class="s3">255 </span>* cam))

<span class="s0">class </span>GradCam:
	<span class="s0">def </span>__init__(self, model, target_layer_names, use_cuda):
		self.model = model
		self.model.eval()
		self.cuda = use_cuda
		<span class="s0">if </span>self.cuda:
			self.model = model.cuda()

		self.extractor = ModelOutputs(self.model, target_layer_names)

	<span class="s0">def </span>forward(self, input):
		<span class="s0">return </span>self.model(input)

	<span class="s0">def </span>__call__(self, input, index = <span class="s0">None</span>):
		<span class="s0">if </span>self.cuda:
			features, output = self.extractor(input.cuda())
		<span class="s0">else</span>:
			features, output = self.extractor(input)

		<span class="s0">if </span>index == <span class="s0">None</span>:
			index = np.argmax(output.cpu().data.numpy())

		one_hot = np.zeros((<span class="s3">1</span>, output.size()[-<span class="s3">1</span>]), dtype = np.float32)
		one_hot[<span class="s3">0</span>][index] = <span class="s3">1</span>
		one_hot = Variable(torch.from_numpy(one_hot), requires_grad = <span class="s0">True</span>)
		<span class="s0">if </span>self.cuda:
			one_hot = torch.sum(one_hot.cuda() * output)
		<span class="s0">else</span>:
			one_hot = torch.sum(one_hot * output)

		self.model.features.zero_grad()
		self.model.classifier.zero_grad()
		one_hot.backward()

		grads_val = self.extractor.get_gradients()[-<span class="s3">1</span>].cpu().data.numpy()

		target = features[-<span class="s3">1</span>]
		target = target.cpu().data.numpy()[<span class="s3">0</span>, :]

		weights = np.mean(grads_val, axis = (<span class="s3">2</span>, <span class="s3">3</span>))[<span class="s3">0</span>, :]
		cam = np.zeros(target.shape[<span class="s3">1 </span>: ], dtype = np.float32)

		<span class="s0">for </span>i, w <span class="s0">in </span>enumerate(weights):
			cam += w * target[i, :, :]

		cam = np.maximum(cam, <span class="s3">0</span>)
		cam = cv2.resize(cam, (<span class="s3">224</span>, <span class="s3">224</span>))
		cam = cam - np.min(cam)
		cam = cam / np.max(cam)
		<span class="s0">return </span>cam

<span class="s0">class </span>GuidedBackpropReLU(Function):

    <span class="s0">def </span>forward(self, input):
        positive_mask = (input &gt; <span class="s3">0</span>).type_as(input)
        output = torch.addcmul(torch.zeros(input.size()).type_as(input), input, positive_mask)
        self.save_for_backward(input, output)
        <span class="s0">return </span>output

    <span class="s0">def </span>backward(self, grad_output):
        input, output = self.saved_tensors
        grad_input = <span class="s0">None</span>

        positive_mask_1 = (input &gt; <span class="s3">0</span>).type_as(grad_output)
        positive_mask_2 = (grad_output &gt; <span class="s3">0</span>).type_as(grad_output)
        grad_input = torch.addcmul(torch.zeros(input.size()).type_as(input), torch.addcmul(torch.zeros(input.size()).type_as(input), grad_output, positive_mask_1), positive_mask_2)

        <span class="s0">return </span>grad_input

<span class="s0">class </span>GuidedBackpropReLUModel:
	<span class="s0">def </span>__init__(self, model, use_cuda):
		self.model = model
		self.model.eval()
		self.cuda = use_cuda
		<span class="s0">if </span>self.cuda:
			self.model = model.cuda()

		<span class="s2"># replace ReLU with GuidedBackpropReLU</span>
		<span class="s0">for </span>idx, module <span class="s0">in </span>self.model.features._modules.items():
			<span class="s0">if </span>module.__class__.__name__ == <span class="s4">'ReLU'</span>:
				self.model.features._modules[idx] = GuidedBackpropReLU()

	<span class="s0">def </span>forward(self, input):
		<span class="s0">return </span>self.model(input)

	<span class="s0">def </span>__call__(self, input, index = <span class="s0">None</span>):
		<span class="s0">if </span>self.cuda:
			output = self.forward(input.cuda())
		<span class="s0">else</span>:
			output = self.forward(input)

		<span class="s0">if </span>index == <span class="s0">None</span>:
			index = np.argmax(output.cpu().data.numpy())

		one_hot = np.zeros((<span class="s3">1</span>, output.size()[-<span class="s3">1</span>]), dtype = np.float32)
		one_hot[<span class="s3">0</span>][index] = <span class="s3">1</span>
		one_hot = Variable(torch.from_numpy(one_hot), requires_grad = <span class="s0">True</span>)
		<span class="s0">if </span>self.cuda:
			one_hot = torch.sum(one_hot.cuda() * output)
		<span class="s0">else</span>:
			one_hot = torch.sum(one_hot * output)

		<span class="s2"># self.model.features.zero_grad()</span>
		# self.model.classifier.zero_grad()
		one_hot.backward()

		output = input.grad.cpu().data.numpy()
		output = output[<span class="s3">0</span>,:,:,:]

		<span class="s0">return </span>output

<span class="s0">def </span>get_args():
	parser = argparse.ArgumentParser()
	parser.add_argument(<span class="s4">'--use-cuda'</span>, action=<span class="s4">'store_true'</span>, default=<span class="s0">False</span>,
	                    help=<span class="s4">'Use NVIDIA GPU acceleration'</span>)
	parser.add_argument(<span class="s4">'--image-path'</span>, type=str, default=<span class="s4">'./examples/both.png'</span>,
	                    help=<span class="s4">'Input image path'</span>)
	args = parser.parse_args()
	args.use_cuda = args.use_cuda <span class="s0">and </span>torch.cuda.is_available()
	<span class="s0">if </span>args.use_cuda:
	    print(<span class="s4">&quot;Using GPU for acceleration&quot;</span>)
	<span class="s0">else</span>:
	    print(<span class="s4">&quot;Using CPU for computation&quot;</span>)

	<span class="s0">return </span>args

<span class="s0">if </span>__name__ == <span class="s4">'__main__'</span>:
	<span class="s4">&quot;&quot;&quot; python grad_cam.py &lt;path_to_image&gt; 
    1. Loads an image with opencv. 
    2. Preprocesses it for VGG19 and converts to a pytorch variable. 
    3. Makes a forward pass to find the category index with the highest score, 
    and computes intermediate activations. 
    Makes the visualization. &quot;&quot;&quot;</span>

	args = <span class="s4">&quot;/Users/remosy/Desktop/test1.png&quot;</span>

	<span class="s2"># Can work with any model, but it assumes that the model has a</span>
	# feature method, and a classifier method,
	# as in the VGG models in torchvision.
	grad_cam = GradCam(model = models.vgg19(pretrained=<span class="s0">True</span>), \
					target_layer_names = [<span class="s4">&quot;35&quot;</span>], use_cuda=<span class="s0">False</span>)

	img = cv2.imread(args, <span class="s3">1</span>)
	img = np.float32(cv2.resize(img, (<span class="s3">224</span>, <span class="s3">224</span>))) / <span class="s3">255</span>
	input = preprocess_image(img)

	<span class="s2"># If None, returns the map for the highest scoring category.</span>
	# Otherwise, targets the requested index.
	target_index = <span class="s0">None</span>

	mask = grad_cam(input, target_index)

	show_cam_on_image(img, mask)

	gb_model = GuidedBackpropReLUModel(model = models.vgg19(pretrained=<span class="s0">True</span>), use_cuda=<span class="s0">False</span>)
	gb = gb_model(input, index=target_index)
	utils.save_image(torch.from_numpy(gb), <span class="s4">'gb.jpg'</span>)

	cam_mask = np.zeros(gb.shape)
	<span class="s0">for </span>i <span class="s0">in </span>range(<span class="s3">0</span>, gb.shape[<span class="s3">0</span>]):
	    cam_mask[i, :, :] = mask

	cam_gb = np.multiply(cam_mask, gb)
	utils.save_image(torch.from_numpy(cam_gb), <span class="s4">'cam_gb.jpg'</span>)</pre>
</body>
</html>